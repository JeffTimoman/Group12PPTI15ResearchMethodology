{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgtmqpLsmNyO4g46iuLfPn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"MSzRcoMdP7oj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U -q evaluate transformers datasets>=2.14.5 accelerate>=0.27 2>/dev/null"],"metadata":{"id":"m1NKT3HVP-mI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importing necessary libraries and modules\n","import warnings  # Import the 'warnings' module for handling warnings\n","warnings.filterwarnings(\"ignore\")  # Ignore warnings during execution\n","\n","import gc  # Import the 'gc' module for garbage collection\n","import numpy as np  # Import NumPy for numerical operations\n","import pandas as pd  # Import Pandas for data manipulation\n","import itertools\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import (\n","    accuracy_score,\n","    roc_auc_score,\n","    confusion_matrix,\n","    classification_report,\n","    f1_score\n",")\n","\n","from imblearn.over_sampling import RandomOverSampler # import RandomOverSampler\n","import accelerate # Import the 'accelerate' module\n","import evaluate  # Import the 'evaluate' module\n","from datasets import Dataset, Image, ClassLabel  # Import custom 'Dataset', 'ClassLabel', and 'Image' classes\n","from transformers import (  # Import various modules from the Transformers library\n","    TrainingArguments,  # For training arguments\n","    Trainer,  # For model training\n","    ViTImageProcessor,  # For processing image data with ViT models\n","    ViTForImageClassification,  # ViT model for image classification\n","    DefaultDataCollator  # For collating data in the default way\n",")\n","import torch  # Import PyTorch for deep learning\n","from torch.utils.data import DataLoader  # For creating data loaders\n","from torchvision.transforms import (  # Import image transformation functions\n","    CenterCrop,  # Center crop an image\n","    Compose,  # Compose multiple image transformations\n","    Normalize,  # Normalize image pixel values\n","    RandomRotation,  # Apply random rotation to images\n","    RandomResizedCrop,  # Crop and resize images randomly\n","    RandomHorizontalFlip,  # Apply random horizontal flip\n","    RandomAdjustSharpness,  # Adjust sharpness randomly\n","    Resize,  # Resize images\n","    ToTensor  # Convert images to PyTorch tensors\n",")"],"metadata":{"id":"y6UqtW4wQArD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import the necessary module from the Python Imaging Library (PIL).\n","from PIL import ImageFile\n","\n","# Enable the option to load truncated images.\n","# This setting allows the PIL library to attempt loading images even if they are corrupted or incomplete.\n","ImageFile.LOAD_TRUNCATED_IMAGES = True"],"metadata":{"id":"wLhCDc9GQCgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","from tqdm import tqdm\n","import os"],"metadata":{"id":"uRWgrbg-QE7h"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D_9eQm-OPlHX"},"outputs":[],"source":["\n","\n","# Initialize lists for file names and labels\n","file_names = []\n","labels = []\n","for file in sorted(Path('./dataset').glob('*/*.*')):\n","    sample_dir = '/'.join(str(file).split('/')[:-1])+'/'\n","    file_names.append(str(file))\n","    label = str(file).split('/')[-2]\n","    labels.append(label)\n","\n","print(len(file_names), len(labels), len(set(labels)))\n","df = pd.DataFrame.from_dict({\"image\": file_names, \"label\": labels})\n","\n","# Specify the labels you want to keep\n","labels_to_keep = ['Amanita pantherina', 'Amanita rubescens', 'Apioperdon pyriforme', 'Armillaria borealis',\n","                  'Artomyces pyxidatus', 'Bjerkandera adusta', 'Boletus edulis', 'Boletus reticulatus',\n","                  'Calocera viscosa', 'Calycina citrina', 'Cantharellus cibarius', 'Cetraria islandica',\n","                  'Chlorociboria aeruginascens', 'Chondrostereum purpureum', 'Cladonia fimbriata',\n","                  'Cladonia rangiferina', 'Cladonia stellaris', 'Clitocybe nebularis', 'Coltricia perennis',\n","                  'Coprinellus disseminatus', 'Coprinellus micaceus', 'Coprinopsis atramentaria', 'Crucibulum laeve',\n","                  'Daedaleopsis confragosa', 'Daedaleopsis tricolor', 'Ganoderma applanatum', 'Graphis scripta',\n","                  'Gyromitra esculenta', 'Gyromitra infula', 'Hygrophoropsis aurantiaca']\n","\n","# Filter the DataFrame\n","df = df[df['label'].isin(labels_to_keep)]\n","print(df.shape)\n","\n","# Oversample minority classes\n","y = df[['label']]\n","df = df.drop(['label'], axis=1)\n","ros = RandomOverSampler(random_state=83)\n","df, y_resampled = ros.fit_resample(df, y)\n","df['label'] = y_resampled\n","gc.collect()\n","\n","print(df.shape)\n","labels_list = sorted(set(labels_to_keep))\n","label2id = {label: i for i, label in enumerate(labels_list)}\n","id2label = {i: label for i, label in enumerate(labels_list)}\n","\n","print(\"Mapping of IDs to Labels:\", id2label, '\\n')\n","print(\"Mapping of Labels to IDs:\", label2id)\n","\n","ClassLabels = ClassLabel(num_classes=len(labels_list), names=labels_list)\n","\n","def map_label2id(example):\n","    example['label'] = ClassLabels.str2int(example['label'])\n","    return example\n","\n","dataset = Dataset.from_pandas(df)\n","dataset = dataset.map(map_label2id, batched=True)\n","dataset = dataset.cast_column('label', ClassLabels)\n","dataset = dataset.train_test_split(test_size=0.3, shuffle=True, stratify_by_column=\"label\")\n","\n","train_data = dataset['train']\n","test_data = dataset['test']\n","model_str =  'google/vit-base-patch16-224-in21k'\n","\n","processor = ViTImageProcessor.from_pretrained(model_str)\n","image_mean, image_std = processor.image_mean, processor.image_std\n","size = processor.size[\"height\"]\n","print(\"Size: \", size)\n","normalize = Normalize(mean=image_mean, std=image_std)\n","\n","# Transformations, converting grayscale back to RGB by replication of channels\n","_train_transforms = Compose([\n","    Resize((size, size)),\n","    RandomRotation(90),\n","    RandomAdjustSharpness(2),\n","    Lambda(lambda x: x.convert(\"L\").convert(\"RGB\")),  # convert to grayscale and then RGB\n","    ToTensor(),\n","    normalize\n","])\n","\n","_val_transforms = Compose([\n","    Resize((size, size)),\n","    Lambda(lambda x: x.convert(\"L\").convert(\"RGB\")),  # convert to grayscale and then RGB\n","    ToTensor(),\n","    normalize\n","])\n","\n","def train_transforms(examples):\n","    examples['pixel_values'] = [_train_transforms(Image.open(image_path)) for image_path in examples['image']]\n","    return examples\n","\n","def val_transforms(examples):\n","    examples['pixel_values'] = [_val_transforms(Image.open(image_path)) for image_path in examples['image']]\n","    return examples\n","\n","train_data.set_transform(train_transforms)\n","test_data.set_transform(val_transforms)\n","\n","def collate_fn(examples):\n","    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n","    labels = torch.tensor([example['label'] for example in examples])\n","    return {\"pixel_values\": pixel_values, \"labels\": labels}\n","\n","model = ViTForImageClassification.from_pretrained(model_str, num_labels=len(labels_list))\n","model.config.id2label = id2label\n","model.config.label2id = label2id\n","print(model.num_parameters(only_trainable=True) / 1e6)\n","\n","accuracy = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    predictions = eval_pred.predictions\n","    label_ids = eval_pred.label_ids\n","    predicted_labels = predictions.argmax(axis=1)\n","    acc_score = accuracy.compute(predictions=predicted_labels, references=label_ids)['accuracy']\n","    return {\"accuracy\": acc_score}\n","\n","metric_name = \"accuracy\"\n","model_name = \"mushrooms_image_detection\"\n","num_train_epochs = 1\n","\n","args = TrainingArguments(\n","    output_dir=model_name,\n","    logging_dir='./logs',\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-7,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=num_train_epochs,\n","    weight_decay=0.02,\n","    warmup_steps=50,\n","    remove_unused_columns=False,\n","    save_strategy='epoch',\n","    load_best_model_at_end=True,\n","    save_total_limit=1,\n","    report_to=\"none\"\n",")\n","\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=train_data,\n","    eval_dataset=test_data,\n","    data_collator=collate_fn,\n","    compute_metrics=compute_metrics,\n","    tokenizer=processor,\n",")\n","\n","trainer.evaluate()\n","outputs = trainer.predict(test_data)\n","print(outputs.metrics)\n"]},{"cell_type":"code","source":["y_true = outputs.label_ids\n","\n","y_pred = outputs.predictions.argmax(1)\n","\n","accuracy = accuracy_score(y_true, y_pred)\n","f1 = f1_score(y_true, y_pred, average='macro')\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print()\n","print(\"Classification report:\")\n","print()\n","print(classification_report(y_true, y_pred, target_names=labels_list, digits=4))"],"metadata":{"id":"GDWa0KnYQQn_"},"execution_count":null,"outputs":[]}]}